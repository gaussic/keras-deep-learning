{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单词级 one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "token_index = {}\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros(shape=(len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'the': 5,\n",
       " 'mat.': 6,\n",
       " 'dog': 7,\n",
       " 'ate': 8,\n",
       " 'my': 9,\n",
       " 'homework.': 10}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符级 one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "characters = string.printable\n",
    "token_index = dict(zip(characters, range(1, len(characters) + 1)))\n",
    "\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1.\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras 实现单词级的 one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique tokens.\n",
      "One-hot results:\n",
      " [[0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "Word index: {'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print('One-hot results:\\n', one_hot_results)\n",
    "print('Word index:', word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用散列技巧的单词级的 one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "dimensionality = 1000\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality\n",
    "        results[i, j, index] = 1.\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用词嵌入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例化一个 Embedding 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载 IMDB 数据，准备用于 Embedding 层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 20), (25000, 20))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在 IMDB 数据上使用 Embedding 层和分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 93us/step - loss: 0.6759 - acc: 0.6052 - val_loss: 0.6399 - val_acc: 0.6806\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s 82us/step - loss: 0.5660 - acc: 0.7429 - val_loss: 0.5470 - val_acc: 0.7194\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 0.4753 - acc: 0.7807 - val_loss: 0.5115 - val_acc: 0.7382\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 0.4263 - acc: 0.8079 - val_loss: 0.5009 - val_acc: 0.7442\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 2s 92us/step - loss: 0.3929 - acc: 0.8260 - val_loss: 0.4982 - val_acc: 0.7536\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 0.3665 - acc: 0.8400 - val_loss: 0.5015 - val_acc: 0.7528\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 2s 105us/step - loss: 0.3431 - acc: 0.8538 - val_loss: 0.5054 - val_acc: 0.7526\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 2s 113us/step - loss: 0.3218 - acc: 0.8657 - val_loss: 0.5134 - val_acc: 0.7478\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 2s 88us/step - loss: 0.3017 - acc: 0.8770 - val_loss: 0.5217 - val_acc: 0.7486\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s 85us/step - loss: 0.2833 - acc: 0.8860 - val_loss: 0.5307 - val_acc: 0.7466\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整合到一起，从原始文本到词嵌入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理 IMDB 原始数据的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = 'data/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf-8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对 IMDB 原始数据的文本进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n",
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100\n",
    "training_samples = 200\n",
    "validation_samples = 10000\n",
    "max_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解析 GloVe 词嵌入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = 'data/glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备 GloVe 词嵌入矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将与训练的词嵌入加载到 Embedding 层中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 320,065\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8123 - val_acc: 0.5235\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4222e-04 - acc: 1.0000 - val_loss: 0.8121 - val_acc: 0.5298\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 7.3513e-05 - acc: 1.0000 - val_loss: 0.8190 - val_acc: 0.5313\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 4.5397e-05 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 0.5323\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.9461e-05 - acc: 1.0000 - val_loss: 0.8407 - val_acc: 0.5297\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.9818e-05 - acc: 1.0000 - val_loss: 0.8458 - val_acc: 0.5302\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3357e-05 - acc: 1.0000 - val_loss: 0.8514 - val_acc: 0.5310\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 9.3571e-06 - acc: 1.0000 - val_loss: 0.8536 - val_acc: 0.5341\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 6.6486e-06 - acc: 1.0000 - val_loss: 0.8642 - val_acc: 0.5321\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 4.8030e-06 - acc: 1.0000 - val_loss: 0.8727 - val_acc: 0.5321\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 绘制结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation acc\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在不使用预训练词嵌入的情况下，训练相同的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.6974 - acc: 0.4250 - val_loss: 0.6929 - val_acc: 0.5131\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.5136 - acc: 0.9800 - val_loss: 0.6927 - val_acc: 0.5177\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.2984 - acc: 0.9950 - val_loss: 0.7083 - val_acc: 0.5145\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.1307 - acc: 1.0000 - val_loss: 0.7116 - val_acc: 0.5243\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0595 - acc: 1.0000 - val_loss: 0.7051 - val_acc: 0.5256\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.7200 - val_acc: 0.5256\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.7259 - val_acc: 0.5264\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.5241\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.7475 - val_acc: 0.5262\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.7503 - val_acc: 0.5261\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对测试集数据进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf-8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "                \n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在测试集上评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 114us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8722183459472657, 0.53444]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
